# -*- coding: utf-8 -*-
"""Group Assingment#2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16oCX6zrHu6ymTDpO1FAUBakMOcApTWB7
"""

# import the library
import pandas as pd
# read the output

output = pd.read_csv('trainset.csv')
output

input = pd.read_csv('testset.csv')
input

# Data Exploration - Calculate statistics for numerical columns in data
numerical_features= ['age','duration','campaign','pdays','nr.employed']
print(output[numerical_features].describe())

# Data Exploration - Grouping the data by the target attribute and calculating the mean for each numerical category
target = output['Subscribed']
grouped_summary = output.groupby(target)[numerical_features].mean()
print(grouped_summary)

# Data Exploration - Checking the distribution of the target atttribute
target_distribution = output['Subscribed'].value_counts()
print(target_distribution)

# Data Exploration - Graphs for the numerical features of the data
import matplotlib.pyplot as plt
import seaborn as sns

for feature in numerical_features:
    plt.figure(figsize=(8, 4))
    sns.histplot(output[feature], kde=True, bins=30, color="blue", alpha=0.7)
    plt.title(f"Distribution of {feature}")
    plt.xlabel(feature)
    plt.ylabel("Frequency")
    plt.grid(axis='y')
    plt.show()

# Data Exploration - Bar chart for the target distribution data
sns.countplot(data=output, x=target, palette="viridis")
plt.title(f"Target Attribute: {target} Distribution")
plt.xlabel(target)
plt.ylabel("Count")
plt.show()

# Preprocessing the data - Count the number of unknown values in each column
unknown_values = (output == 'unknown').sum()
print(unknown_values)

# Preprocessing the data - Drop the rows with unknown values in them
output_cleaned = output[output.isin(['unknown']).any(axis=1)]

# Preprocessing the data - Check rows for missing values
missing_values = output.isnull().sum()
print(missing_values)

# Preprocessing the data - Drop the rows with missing values
output_data_cleaned = output.dropna()

# Preprocessing the data - Encode for each of the features
from sklearn.preprocessing import LabelEncoder
categorical_columns = output_data_cleaned.select_dtypes(include=['object']).columns
# Apply LabelEncoder to each categorical column
label_encoder = LabelEncoder()
for column in categorical_columns:
    output_data_cleaned[column] = label_encoder.fit_transform(output_data_cleaned[column])

from sklearn.model_selection import train_test_split

# Separated features (X) and target variable (y)
X = output_data_cleaned[['age','job','marital','education','housing','loan','contact','month','day_of_week','duration', 'campaign', 'pdays', 'poutcome', 'nr.employed', 'Subscribed']]
Y = output_data_cleaned['Subscribed']

print(len(output))

# Train a decision classifier
from sklearn.tree import DecisionTreeClassifier
clf = DecisionTreeClassifier(random_state=42)
clf.fit(X,Y)

# Initialize the regression model
from sklearn.linear_model import LogisticRegression
logreg = LogisticRegression(random_state=42)

# Train the model
logreg.fit(X,Y)

# Make predictions on the train set
Pred_y = logreg.predict(X)

#Evaluate the regression model and display the results
from sklearn.metrics import accuracy_score, confusion_matrix,recall_score,precision_score
Accuracy = accuracy_score(Y, Pred_y)
Confusion_matrix = confusion_matrix(Y, Pred_y)
recall_score=recall_score(Y, Pred_y)
precision_score=precision_score(Y, Pred_y)



print("Accuracy:", Accuracy)


print("Recall Score:", recall_score)
print("Precision:", precision_score)



print("Confusion Matrix:\n", Confusion_matrix)

from sklearn.tree import plot_tree

# Plot the decision tree
plt.figure(figsize=(20, 10))  # Adjust the figure size as needed
plot_tree(
    clf,
    feature_names=X.columns,
    class_names=['Not Subscribed', 'Subscribed'],
    filled=True,
    rounded=True,
    fontsize=10
)
plt.title("Decision Tree Visualization")
plt.show()

#Input cleaning and organization for testing purposes

# Data Exploration - Calculate statistics for numerical columns in data
numerical_features= ['age','duration','campaign','pdays','nr.employed']
print(input[numerical_features].describe())

# Data Exploration - Grouping the data by the target attribute and calculating the mean for each numerical category
target = input['Subscribed']
grouped_summary = input.groupby(target)[numerical_features].mean()
print(grouped_summary)

# Data Exploration - Checking the distribution of the target atttribute
target_distribution = input['Subscribed'].value_counts()
print(target_distribution)

# Preprocessing the data - Count the number of unknown values in each column
unknown_values = (input == 'unknown').sum()
print(unknown_values)

# Preprocessing the data - Drop the rows with unknown values in them
input_cleaned = input[input.isin(['unknown']).any(axis=1)]

# Preprocessing the data - Check rows for missing values
missing_values = input.isnull().sum()
print(missing_values)

# Preprocessing the data - Drop the rows with missing values
input_data_cleaned = input.dropna()

# Preprocessing the data - Encode for each of the features
from sklearn.preprocessing import LabelEncoder
categorical_columns = input_data_cleaned.select_dtypes(include=['object']).columns
# Apply LabelEncoder to each categorical column
label_encoder = LabelEncoder()
for column in categorical_columns:
    input_data_cleaned[column] = label_encoder.fit_transform(input_data_cleaned[column])

from sklearn.model_selection import train_test_split

# Separated features (X) and target variable (y)
X_input = input_data_cleaned[['age','job','marital','education','housing','loan','contact','month','day_of_week','duration', 'campaign', 'pdays', 'poutcome', 'nr.employed', 'Subscribed']]
Y_input = input_data_cleaned['Subscribed']

print(len(input))

# Make predictions on the train set
Pred1_y = logreg.predict(X_input)

#Evaluate the test set and display the results
from sklearn.metrics import accuracy_score, confusion_matrix,recall_score,precision_score
Accuracy1 = accuracy_score(Y_input, Pred1_y)
Confusion_matrix1 = confusion_matrix(Y_input, Pred1_y)
recall_score1=recall_score(Y_input, Pred1_y)
precision_score1=precision_score(Y_input, Pred1_y)



print("Accuracy:", Accuracy1)


print("Recall Score:", recall_score1)
print("Precision:", precision_score1)



print("Confusion Matrix:\n", Confusion_matrix1)